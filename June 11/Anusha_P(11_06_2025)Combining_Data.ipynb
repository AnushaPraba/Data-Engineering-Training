{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PySpark Exercises â€“ Set 3 (Project, Nulls, Functions)"
      ],
      "metadata": {
        "id": "q_avfFHilFx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "4KkVb7rflHy3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"Ananya\", \"HR\", 52000),\n",
        "    (\"Rahul\", \"Engineering\", 65000),\n",
        "    (\"Priya\", \"Engineering\", 60000),\n",
        "    (\"Zoya\", \"Marketing\", 48000),\n",
        "    (\"Karan\", \"HR\", 53000),\n",
        "    (\"Naveen\", \"Engineering\", 70000),\n",
        "    (\"Fatima\", \"Marketing\", 45000)\n",
        "]\n",
        "columns = [\"Name\", \"Department\", \"Salary\"]\n",
        "df_emp = spark.createDataFrame(data, columns)\n",
        "df_emp.show()\n",
        "performance = [\n",
        "    (\"Ananya\", 2023, 4.5),\n",
        "    (\"Rahul\", 2023, 4.9),\n",
        "    (\"Priya\", 2023, 4.3),\n",
        "    (\"Zoya\", 2023, 3.8),\n",
        "    (\"Karan\", 2023, 4.1),\n",
        "    (\"Naveen\", 2023, 4.7),\n",
        "    (\"Fatima\", 2023, 3.9)\n",
        "]\n",
        "columns_perf = [\"Name\", \"Year\", \"Rating\"]\n",
        "df_perf = spark.createDataFrame(performance, columns_perf)\n",
        "df_perf.show()\n",
        "project_data = [\n",
        "(\"Ananya\", \"HR Portal\", 120),\n",
        "(\"Rahul\", \"Data Platform\", 200),\n",
        "(\"Priya\", \"Data Platform\", 180),\n",
        "(\"Zoya\", \"Campaign Tracker\", 100),\n",
        "(\"Karan\", \"HR Portal\", 130),\n",
        "(\"Naveen\", \"ML Pipeline\", 220),\n",
        "(\"Fatima\", \"Campaign Tracker\", 90)\n",
        "]\n",
        "columns_proj = [\"Name\", \"Project\", \"HoursWorked\"]\n",
        "df_proj = spark.createDataFrame(project_data, columns_proj)\n",
        "df_proj.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPHL9S6elOD1",
        "outputId": "f7d652bf-8193-40c3-eccd-254ebfe23ec2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+\n",
            "|  Name| Department|Salary|\n",
            "+------+-----------+------+\n",
            "|Ananya|         HR| 52000|\n",
            "| Rahul|Engineering| 65000|\n",
            "| Priya|Engineering| 60000|\n",
            "|  Zoya|  Marketing| 48000|\n",
            "| Karan|         HR| 53000|\n",
            "|Naveen|Engineering| 70000|\n",
            "|Fatima|  Marketing| 45000|\n",
            "+------+-----------+------+\n",
            "\n",
            "+------+----+------+\n",
            "|  Name|Year|Rating|\n",
            "+------+----+------+\n",
            "|Ananya|2023|   4.5|\n",
            "| Rahul|2023|   4.9|\n",
            "| Priya|2023|   4.3|\n",
            "|  Zoya|2023|   3.8|\n",
            "| Karan|2023|   4.1|\n",
            "|Naveen|2023|   4.7|\n",
            "|Fatima|2023|   3.9|\n",
            "+------+----+------+\n",
            "\n",
            "+------+----------------+-----------+\n",
            "|  Name|         Project|HoursWorked|\n",
            "+------+----------------+-----------+\n",
            "|Ananya|       HR Portal|        120|\n",
            "| Rahul|   Data Platform|        200|\n",
            "| Priya|   Data Platform|        180|\n",
            "|  Zoya|Campaign Tracker|        100|\n",
            "| Karan|       HR Portal|        130|\n",
            "|Naveen|     ML Pipeline|        220|\n",
            "|Fatima|Campaign Tracker|         90|\n",
            "+------+----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joins and Advanced Aggregations"
      ],
      "metadata": {
        "id": "lUxFKN41lfbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Join employee_data , performance_data , and project_data .\n",
        "df_joined=df_emp.join(df_perf, \"Name\").join(df_proj, \"Name\")\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgWEUiQIleiS",
        "outputId": "de8e2b6d-87e7-449d-9417-20f86064750d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----+------+----------------+-----------+\n",
            "|  Name| Department|Salary|Year|Rating|         Project|HoursWorked|\n",
            "+------+-----------+------+----+------+----------------+-----------+\n",
            "|Ananya|         HR| 52000|2023|   4.5|       HR Portal|        120|\n",
            "| Priya|Engineering| 60000|2023|   4.3|   Data Platform|        180|\n",
            "| Rahul|Engineering| 65000|2023|   4.9|   Data Platform|        200|\n",
            "|Naveen|Engineering| 70000|2023|   4.7|     ML Pipeline|        220|\n",
            "|Fatima|  Marketing| 45000|2023|   3.9|Campaign Tracker|         90|\n",
            "|  Zoya|  Marketing| 48000|2023|   3.8|Campaign Tracker|        100|\n",
            "| Karan|         HR| 53000|2023|   4.1|       HR Portal|        130|\n",
            "+------+-----------+------+----+------+----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Compute total hours worked per department.\n",
        "from pyspark.sql.functions import sum\n",
        "total_hours_per_dept = df_proj.groupBy(\"Project\").agg(sum(\"HoursWorked\").alias(\"TotalHoursWorked\"))\n",
        "total_hours_per_dept.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yys5rCjjloQ3",
        "outputId": "bd3254c4-4552-45f6-ba4a-93785aa97b67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+\n",
            "|         Project|TotalHoursWorked|\n",
            "+----------------+----------------+\n",
            "|   Data Platform|             380|\n",
            "|       HR Portal|             250|\n",
            "|     ML Pipeline|             220|\n",
            "|Campaign Tracker|             190|\n",
            "+----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Compute average rating per project.\n",
        "from pyspark.sql.functions import avg\n",
        "avg_rating_per_project = df_joined.groupBy(\"Project\").agg(avg(\"Rating\").alias(\"AverageRating\"))\n",
        "avg_rating_per_project.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kzEKIxVlzfn",
        "outputId": "4923584a-ac73-4afa-d857-97626e196592"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+\n",
            "|         Project|     AverageRating|\n",
            "+----------------+------------------+\n",
            "|   Data Platform|               4.6|\n",
            "|       HR Portal|               4.3|\n",
            "|     ML Pipeline|               4.7|\n",
            "|Campaign Tracker|3.8499999999999996|\n",
            "+----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Missing Data (introduce some manually)"
      ],
      "metadata": {
        "id": "2wIOZ34ml4q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Add a row to performance_data with a None rating.\n",
        "from pyspark.sql import Row\n",
        "new_row = Row(\"Meena\", 2023, None)\n",
        "df_perf_null = df_perf.union(spark.createDataFrame([new_row], df_perf.schema))\n",
        "df_perf_null.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI5lhnwUmHeJ",
        "outputId": "23568fc3-c88c-4bc0-ef64-7115d1ef290f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------+\n",
            "|  Name|Year|Rating|\n",
            "+------+----+------+\n",
            "|Ananya|2023|   4.5|\n",
            "| Rahul|2023|   4.9|\n",
            "| Priya|2023|   4.3|\n",
            "|  Zoya|2023|   3.8|\n",
            "| Karan|2023|   4.1|\n",
            "|Naveen|2023|   4.7|\n",
            "|Fatima|2023|   3.9|\n",
            "| Meena|2023|  NULL|\n",
            "+------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Filter Rows with Null Rating\n",
        "filtered_df = df_perf_null.filter(df_perf_null[\"Rating\"].isNull())\n",
        "filtered_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RShLrk5nmSfb",
        "outputId": "2c8378ae-bf34-444a-bca0-03a612d7b22c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+------+\n",
            "| Name|Year|Rating|\n",
            "+-----+----+------+\n",
            "|Meena|2023|  NULL|\n",
            "+-----+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.Replace Null Ratings with Department Average\n",
        "df_temp = df_emp.join(df_perf_null, \"Name\")\n",
        "dept_avg = df_temp.groupBy(\"Department\").agg(avg(\"Rating\").alias(\"DeptAvg\"))\n",
        "df_filled = df_temp.join(dept_avg, \"Department\").withColumn(\"FilledRating\", when(col(\"Rating\").isNull(), col(\"DeptAvg\")).otherwise(col(\"Rating\"))).drop(\"Rating\").withColumnRenamed(\"FilledRating\", \"Rating\")\n",
        "df_filled.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PE_NVe6mXni",
        "outputId": "ac3ec6cf-82c4-49e2-a236-f47eac7098ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+------+----+------------------+------+\n",
            "| Department|  Name|Salary|Year|           DeptAvg|Rating|\n",
            "+-----------+------+------+----+------------------+------+\n",
            "|Engineering| Rahul| 65000|2023| 4.633333333333334|   4.9|\n",
            "|Engineering| Priya| 60000|2023| 4.633333333333334|   4.3|\n",
            "|Engineering|Naveen| 70000|2023| 4.633333333333334|   4.7|\n",
            "|         HR| Karan| 53000|2023|               4.3|   4.1|\n",
            "|         HR|Ananya| 52000|2023|               4.3|   4.5|\n",
            "|  Marketing|  Zoya| 48000|2023|3.8499999999999996|   3.8|\n",
            "|  Marketing|Fatima| 45000|2023|3.8499999999999996|   3.9|\n",
            "+-----------+------+------+----+------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Built-In Functions and UDF"
      ],
      "metadata": {
        "id": "vaM8ghIUnLrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Create a column PerformanceCategory :\n",
        "# Excellent (>=4.7),\n",
        "# Good (4.0â€“4.69),\n",
        "# Average (<4.0)\n",
        "from pyspark.sql.functions import when\n",
        "df_cat = df_filled.withColumn(\n",
        "    \"PerformanceCategory\",\n",
        "    when(col(\"Rating\") >= 4.7, \"Excellent\")\n",
        "    .when(col(\"Rating\") >= 4.0, \"Good\")\n",
        "    .otherwise(\"Average\"))\n",
        "df_cat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtz1gmgznCWw",
        "outputId": "ab2a2a28-df7d-4bdd-8e68-f0b18ab986b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+------+----+------------------+------+-------------------+\n",
            "| Department|  Name|Salary|Year|           DeptAvg|Rating|PerformanceCategory|\n",
            "+-----------+------+------+----+------------------+------+-------------------+\n",
            "|Engineering| Rahul| 65000|2023| 4.633333333333334|   4.9|          Excellent|\n",
            "|Engineering| Priya| 60000|2023| 4.633333333333334|   4.3|               Good|\n",
            "|Engineering|Naveen| 70000|2023| 4.633333333333334|   4.7|          Excellent|\n",
            "|         HR| Karan| 53000|2023|               4.3|   4.1|               Good|\n",
            "|         HR|Ananya| 52000|2023|               4.3|   4.5|               Good|\n",
            "|  Marketing|  Zoya| 48000|2023|3.8499999999999996|   3.8|            Average|\n",
            "|  Marketing|Fatima| 45000|2023|3.8499999999999996|   3.9|            Average|\n",
            "+-----------+------+------+----+------------------+------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Create a UDF to assign bonus:\n",
        "# If project hours > 200 â†’ 10,000\n",
        "# Else â†’ 5,000\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "def assign_bonus(hours):\n",
        "    return 10000 if hours > 200 else 5000\n",
        "\n",
        "bonus_udf = udf(assign_bonus, IntegerType())\n",
        "df_final = df_joined.withColumn(\"Bonus\", bonus_udf(col(\"HoursWorked\")))\n",
        "df_final.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4CHlQfpnWUz",
        "outputId": "d54559a9-8bf3-4ea9-ade3-3de6061b5dd8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----+------+----------------+-----------+-----+\n",
            "|  Name| Department|Salary|Year|Rating|         Project|HoursWorked|Bonus|\n",
            "+------+-----------+------+----+------+----------------+-----------+-----+\n",
            "|Ananya|         HR| 52000|2023|   4.5|       HR Portal|        120| 5000|\n",
            "| Priya|Engineering| 60000|2023|   4.3|   Data Platform|        180| 5000|\n",
            "| Rahul|Engineering| 65000|2023|   4.9|   Data Platform|        200| 5000|\n",
            "|Naveen|Engineering| 70000|2023|   4.7|     ML Pipeline|        220|10000|\n",
            "|Fatima|  Marketing| 45000|2023|   3.9|Campaign Tracker|         90| 5000|\n",
            "|  Zoya|  Marketing| 48000|2023|   3.8|Campaign Tracker|        100| 5000|\n",
            "| Karan|         HR| 53000|2023|   4.1|       HR Portal|        130| 5000|\n",
            "+------+-----------+------+----+------+----------------+-----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date and Time Functions"
      ],
      "metadata": {
        "id": "908q8K5JnlJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Add a column JoinDate with 2021-06-01 for all, then add MonthsWorked as difference from today.\n",
        "from pyspark.sql.functions import current_date, months_between, to_date, lit\n",
        "df_date = df_final.withColumn(\"JoinDate\", to_date(lit(\"2021-06-01\"))) \\\n",
        "    .withColumn(\"MonthsWorked\", round(months_between(current_date(), col(\"JoinDate\")), 1))\n",
        "df_date.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5P0cp2unnxl",
        "outputId": "437a8106-f756-4a6a-fc96-dc6c28547123"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----+------+----------------+-----------+-----+----------+------------+\n",
            "|  Name| Department|Salary|Year|Rating|         Project|HoursWorked|Bonus|  JoinDate|MonthsWorked|\n",
            "+------+-----------+------+----+------+----------------+-----------+-----+----------+------------+\n",
            "|Ananya|         HR| 52000|2023|   4.5|       HR Portal|        120| 5000|2021-06-01|        48.3|\n",
            "| Priya|Engineering| 60000|2023|   4.3|   Data Platform|        180| 5000|2021-06-01|        48.3|\n",
            "| Rahul|Engineering| 65000|2023|   4.9|   Data Platform|        200| 5000|2021-06-01|        48.3|\n",
            "|Naveen|Engineering| 70000|2023|   4.7|     ML Pipeline|        220|10000|2021-06-01|        48.3|\n",
            "|Fatima|  Marketing| 45000|2023|   3.9|Campaign Tracker|         90| 5000|2021-06-01|        48.3|\n",
            "|  Zoya|  Marketing| 48000|2023|   3.8|Campaign Tracker|        100| 5000|2021-06-01|        48.3|\n",
            "| Karan|         HR| 53000|2023|   4.1|       HR Portal|        130| 5000|2021-06-01|        48.3|\n",
            "+------+-----------+------+----+------+----------------+-----------+-----+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Calculate how many employees joined before 2022.\n",
        "df_date.filter(year(col(\"JoinDate\")) < 2022).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHkjNi9Gn81n",
        "outputId": "8ee57cbd-5f3c-406b-df31-98d9b78261ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unions"
      ],
      "metadata": {
        "id": "FhqnIvZDoHta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Create another small team DataFrame and union() it with employee_data .\n",
        "# extra_employees = [\n",
        "# (\"Meena\", \"HR\", 48000),\n",
        "# (\"Raj\", \"Marketing\", 51000)\n",
        "# ]\n",
        "extra_employees = [(\"Meena\", \"HR\", 48000), (\"Raj\", \"Marketing\", 51000)]\n",
        "df_extra = spark.createDataFrame(extra_employees, [\"Name\", \"Department\", \"Salary\"])\n",
        "df_all = df_emp.union(df_extra)\n",
        "df_all.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_nty1FDoG5Z",
        "outputId": "63e180d9-bf62-427f-f144-37b1fc1c28e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+\n",
            "|  Name| Department|Salary|\n",
            "+------+-----------+------+\n",
            "|Ananya|         HR| 52000|\n",
            "| Rahul|Engineering| 65000|\n",
            "| Priya|Engineering| 60000|\n",
            "|  Zoya|  Marketing| 48000|\n",
            "| Karan|         HR| 53000|\n",
            "|Naveen|Engineering| 70000|\n",
            "|Fatima|  Marketing| 45000|\n",
            "| Meena|         HR| 48000|\n",
            "|   Raj|  Marketing| 51000|\n",
            "+------+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving Results"
      ],
      "metadata": {
        "id": "i355dZ4QoVu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Save the final merged dataset (all 3 joins) as a partitioned Parquet file based on Department .\n",
        "df_date.write.mode(\"overwrite\").parquet(\"final_employee_data\")"
      ],
      "metadata": {
        "id": "LKG2RAGvoSQ6"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}