{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0NpIGiv6dZ6h"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk5URYUFeij9",
        "outputId": "4000aca8-410b-4efd-c5fa-38e7f9492e9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ingestion & Exploration"
      ],
      "metadata": {
        "id": "IxuFPyjBfEAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read all 3 files (CSV + JSON) using PySpark.\n",
        "employees_df=spark.read.csv('/content/drive/MyDrive/employees.csv',header=True,inferSchema=True)\n",
        "attendance_df=spark.read.csv('/content/drive/MyDrive/attendance.csv',header=True,inferSchema=True)\n",
        "bonuses_df=spark.read.json('/content/drive/MyDrive/bonuses.json',multiLine=True)"
      ],
      "metadata": {
        "id": "1sd9QHtPfH6n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show schemas and sample records.\n",
        "employees_df.printSchema()\n",
        "employees_df.show()\n",
        "attendance_df.printSchema()\n",
        "attendance_df.show()\n",
        "bonuses_df.printSchema()\n",
        "bonuses_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-al8_JKGkrlA",
        "outputId": "fd669acc-1e1e-4bd5-8da0-174808a07d9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- JoinDate: date (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            " |-- ManagerID: integer (nullable = true)\n",
            "\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|\n",
            "+-----+------+-----------+----------+------+---------+\n",
            "\n",
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Status: string (nullable = true)\n",
            "\n",
            "+-----+----------+-------+\n",
            "|EmpID|      Date| Status|\n",
            "+-----+----------+-------+\n",
            "|    1|2024-04-01|Present|\n",
            "|    1|2024-04-02|Present|\n",
            "|    2|2024-04-01| Absent|\n",
            "|    2|2024-04-02|Present|\n",
            "|    3|2024-04-01|Present|\n",
            "|    3|2024-04-02|Present|\n",
            "|    4|2024-04-01| Absent|\n",
            "|    4|2024-04-02| Absent|\n",
            "|    5|2024-04-01|Present|\n",
            "|    5|2024-04-02|Present|\n",
            "+-----+----------+-------+\n",
            "\n",
            "root\n",
            " |-- Bonus: long (nullable = true)\n",
            " |-- EmpID: long (nullable = true)\n",
            " |-- Year: long (nullable = true)\n",
            "\n",
            "+-----+-----+----+\n",
            "|Bonus|EmpID|Year|\n",
            "+-----+-----+----+\n",
            "| 5000|    1|2023|\n",
            "| 7000|    2|2023|\n",
            "| 6500|    3|2023|\n",
            "| 6000|    4|2023|\n",
            "| 4000|    5|2023|\n",
            "+-----+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count distinct departments.\n",
        "employees_df.select('department').distinct().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dso0Ursk3O9",
        "outputId": "e536a6d9-5c7a-41a6-b269-5fa1e0bfb42a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. DataFrame Operations"
      ],
      "metadata": {
        "id": "lW3KZAZjk-Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column TenureYears using datediff() and round() .\n",
        "from pyspark.sql.functions import datediff, current_date, round\n",
        "\n",
        "employees_df=employees_df.withColumn(\"TenureYears\",round(datediff(current_date(),\"JoinDate\")/365.0,2))\n",
        "employees_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUcSsduClFAi",
        "outputId": "14ef45be-f3b7-4c29-8a2e-f80cca6e48b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43|\n",
            "+-----+------+-----------+----------+------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TotalCompensation = Salary + Bonus.\n",
        "from pyspark.sql.functions import coalesce,lit\n",
        "\n",
        "bonus_df=employees_df.join(bonuses_df,on=\"EmpID\",how=\"left\")\n",
        "bonus_df=bonus_df.withColumn(\"TotalCompensation\",bonus_df[\"Salary\"]+coalesce(bonus_df[\"Bonus\"],lit(0)))\n",
        "bonus_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYoR0uBulXza",
        "outputId": "c4673e0e-b1da-4849-b56b-6359457096ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|            60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter employees with more than 2 years in the company.\n",
        "bonus_df.filter(bonus_df[\"TenureYears\"]>2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgh-mF4imEJG",
        "outputId": "a2ef04af-ddaa-4bee-f5ee-955a3b3b738c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|            60000|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24| 7000|2023|            87000|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92| 6500|2023|            81500|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56| 6000|2023|            66000|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43| 4000|2023|            54000|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show employees who report to a manager ( ManagerID is not null ).\n",
        "bonus_df.filter(bonus_df[\"ManagerID\"].isNotNull()).select(\"EmpID\",\"Name\",\"ManagerID\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0a6hXALmLR4",
        "outputId": "b68a5544-e225-4b2a-936f-baa17a45c225"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+---------+\n",
            "|EmpID|  Name|ManagerID|\n",
            "+-----+------+---------+\n",
            "|    2|   Raj|        1|\n",
            "|    3|Simran|        1|\n",
            "|    4| Aamir|        1|\n",
            "|    5| Nisha|        1|\n",
            "+-----+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Aggregation Tasks"
      ],
      "metadata": {
        "id": "2ox5096xmj5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average salary per department.\n",
        "employees_df.groupBy(\"Department\").avg(\"Salary\").withColumnRenamed(\"avg(Salary)\", \"AvgSalary\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do7llhyKmmJw",
        "outputId": "5137cc49-e2c8-4d65-d506-a8e2f90a2739"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+\n",
            "| Department|AvgSalary|\n",
            "+-----------+---------+\n",
            "|Engineering|  77500.0|\n",
            "|         HR|  52500.0|\n",
            "|  Marketing|  60000.0|\n",
            "+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of employees under each manager.\n",
        "employees_df.groupBy(\"ManagerID\").count().filter(\"ManagerID IS NOT NULL\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DrzYuMkmtTA",
        "outputId": "4d07837a-7e48-4234-9b83-565329f020b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|ManagerID|count|\n",
            "+---------+-----+\n",
            "|        1|    4|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of absences per employee.\n",
        "from pyspark.sql.functions import col\n",
        "attendance_df.filter(col(\"Status\") == \"Absent\").groupBy(\"EmpID\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnWzVwzFm9EE",
        "outputId": "221cd45e-3431-4c29-8b8a-ac399471c54d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|EmpID|count|\n",
            "+-----+-----+\n",
            "|    4|    2|\n",
            "|    2|    1|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Join Tasks"
      ],
      "metadata": {
        "id": "D-7yNpzpnRGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join employees and attendance → Get attendance % (Present days / Total days).\n",
        "from pyspark.sql.functions import count,sum,col,round\n",
        "\n",
        "attendance_stats = attendance_df.withColumn(\"PresentFlag\",(col(\"Status\")==\"Present\").cast(\"int\")).groupBy(\"EmpID\")\\\n",
        "      .agg(count(\"Status\").alias(\"TotalDays\"),sum(\"PresentFlag\").alias(\"PresentDays\")) \\\n",
        "    .withColumn(\"AttendancePercent\",round((col(\"PresentDays\")/col(\"TotalDays\"))*100,2))\n",
        "employees_attendance=employees_df.join(attendance_stats,on=\"EmpID\",how=\"left\")\n",
        "employees_attendance.select(\"EmpID\",\"Name\",\"PresentDays\",\"TotalDays\",\"AttendancePercent\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuKk_SxNnP0Q",
        "outputId": "b5e488ea-d5e7-4fac-fde0-97cbb1337a88"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+---------+-----------------+\n",
            "|EmpID|  Name|PresentDays|TotalDays|AttendancePercent|\n",
            "+-----+------+-----------+---------+-----------------+\n",
            "|    1| Anita|          2|        2|            100.0|\n",
            "|    2|   Raj|          1|        2|             50.0|\n",
            "|    3|Simran|          2|        2|            100.0|\n",
            "|    4| Aamir|          0|        2|              0.0|\n",
            "|    5| Nisha|          2|        2|            100.0|\n",
            "+-----+------+-----------+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join employees and bonuses → Show top 3 employees by TotalCompensation.\n",
        "from pyspark.sql.functions import coalesce\n",
        "\n",
        "bonus_df=employees_df.join(bonuses_df,on=\"EmpID\",how=\"left\").withColumn(\"Bonus\",coalesce(col(\"Bonus\"),lit(0))).withColumn(\"TotalCompensation\",col(\"Salary\")+col(\"Bonus\"))\n",
        "bonus_df.orderBy(col(\"TotalCompensation\").desc()).select(\"EmpID\", \"Name\", \"TotalCompensation\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8qMt0MytSfj",
        "outputId": "3c3ae655-16aa-471d-d989-abe46dc3be5a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------------+\n",
            "|EmpID|  Name|TotalCompensation|\n",
            "+-----+------+-----------------+\n",
            "|    2|   Raj|            87000|\n",
            "|    3|Simran|            81500|\n",
            "|    4| Aamir|            66000|\n",
            "|    1| Anita|            60000|\n",
            "|    5| Nisha|            54000|\n",
            "+-----+------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-level join: employees + bonuses + attendance .\n",
        "multijoin_df=employees_df.join(bonuses_df,on=\"EmpID\",how=\"left\").join(attendance_stats,on=\"EmpID\",how=\"left\")\n",
        "multijoin_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DacxGNY9twRh",
        "outputId": "0c99e879-0796-4b3b-e673-68cdf54b90f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------+-----------+-----------------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalDays|PresentDays|AttendancePercent|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------+-----------+-----------------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|        2|          2|            100.0|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24| 7000|2023|        2|          1|             50.0|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92| 6500|2023|        2|          2|            100.0|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56| 6000|2023|        2|          0|              0.0|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43| 4000|2023|        2|          2|            100.0|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+---------+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. String & Date Functions"
      ],
      "metadata": {
        "id": "QagQPo5DuOAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract year and month from JoinDate .\n",
        "from pyspark.sql.functions import year,month\n",
        "\n",
        "employees_df=employees_df.withColumn(\"JoinYear\",year(\"JoinDate\")).withColumn(\"JoinMonth\",month(\"JoinDate\"))\n",
        "employees_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5kl0b0WuVKh",
        "outputId": "54e4be16-2078-4006-97ce-d55b64bfeee3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11|    2021|        5|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24|    2020|        3|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92|    2022|        7|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56|    2019|       11|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43|    2023|        1|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask employee names using regex.\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "employees_df=employees_df.withColumn(\"MaskedName\",regexp_replace(\"Name\",\"[a-zA-Z]\",\"*\"))\n",
        "employees_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs8tc972uhWy",
        "outputId": "2e3bfda0-2340-47a5-eebb-6b2d06d402c0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11|    2021|        5|     *****|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24|    2020|        3|       ***|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92|    2022|        7|    ******|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56|    2019|       11|     *****|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43|    2023|        1|     *****|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use substring() to create EmpCode like \"EMP001\".\n",
        "from pyspark.sql.functions import lpad,concat,lit\n",
        "employees_df.withColumn(\"EmpCode\", concat(lit(\"EMP\"),lpad(col(\"EmpID\").cast(\"string\"),3,\"0\"))).select(\"EmpID\", \"EmpCode\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke8qQ71muzHg",
        "outputId": "b1db8c98-19e7-4958-9dbf-8f15e9ac53b2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+\n",
            "|EmpID|EmpCode|\n",
            "+-----+-------+\n",
            "|    1| EMP001|\n",
            "|    2| EMP002|\n",
            "|    3| EMP003|\n",
            "|    4| EMP004|\n",
            "|    5| EMP005|\n",
            "+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Conditional & Null Handling\n"
      ],
      "metadata": {
        "id": "dGfN20Crv6Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use when/otherwise to label performance:\n",
        "# “High” if Bonus > 6000\n",
        "# “Medium” if 4000–6000\n",
        "# “Low” otherwise\n",
        "from pyspark.sql.functions import when\n",
        "performance_df=bonus_df.withColumn(\"Performance\",when(col(\"Bonus\")>6000,\"High\").when((col(\"Bonus\")>=4000) & (col(\"Bonus\")<=6000),\"Medium\").otherwise(\"Low\"))\n",
        "performance_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VltaoOoZv--A",
        "outputId": "4934b4e5-a321-4b95-e8c6-8034e12d15d0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|Bonus|Year|TotalCompensation|Performance|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11| 5000|2023|            60000|     Medium|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24| 7000|2023|            87000|       High|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92| 6500|2023|            81500|       High|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56| 6000|2023|            66000|     Medium|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43| 4000|2023|            54000|     Medium|\n",
            "+-----+------+-----------+----------+------+---------+-----------+-----+----+-----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing ManagerID using fillna(\"No Manager\") .\n",
        "employees_df_fill=employees_df.withColumn(\"ManagerID\",when(col(\"ManagerID\").isNull(),\"No Manager\").otherwise(col(\"ManagerID\").cast(\"string\")))\n",
        "employees_df_fill.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENjmPxXFwVOR",
        "outputId": "53af12b0-7b97-44a3-b595-e92efa5ce9aa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+----------+-----------+--------+---------+----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary| ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|\n",
            "+-----+------+-----------+----------+------+----------+-----------+--------+---------+----------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|No Manager|       4.11|    2021|        5|     *****|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|         1|       5.24|    2020|        3|       ***|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|         1|       2.92|    2022|        7|    ******|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|         1|       5.56|    2019|       11|     *****|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|         1|       2.43|    2023|        1|     *****|\n",
            "+-----+------+-----------+----------+------+----------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Spark SQL\n"
      ],
      "metadata": {
        "id": "q4GtL19qyNca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and use database hr.\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS hr\")\n",
        "spark.sql(\"USE hr\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGRfJwNAyG6I",
        "outputId": "232a2b49-0c5b-4c86-a836-9b94a981f960"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all DataFrames as tables: employees , attendance , bonuses .\n",
        "employees_df.write.mode(\"overwrite\").saveAsTable(\"hr.employees\")\n",
        "attendance_df.write.mode(\"overwrite\").saveAsTable(\"hr.attendance\")\n",
        "bonuses_df.write.mode(\"overwrite\").saveAsTable(\"hr.bonuses\")"
      ],
      "metadata": {
        "id": "E1vzazO4ynlE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write SQL queries:\n",
        "# Top paid employee in each department.\n",
        "spark.sql(\"\"\"SELECT * FROM hr.employees WHERE (Department, Salary)\n",
        "          IN (SELECT Department, MAX(Salary) FROM hr.employees\n",
        "          GROUP BY Department)\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcADGnrwy50a",
        "outputId": "f0448e72-8656-4e4c-f16e-cb1b7dc52769"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "|EmpID| Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|\n",
            "+-----+-----+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "|    1|Anita|         HR|2021-05-01| 55000|     NULL|       4.11|    2021|        5|     *****|\n",
            "|    2|  Raj|Engineering|2020-03-15| 80000|        1|       5.24|    2020|        3|       ***|\n",
            "|    4|Aamir|  Marketing|2019-11-20| 60000|        1|       5.56|    2019|       11|     *****|\n",
            "+-----+-----+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write SQL queries:\n",
        "# Attendance rate by department.\n",
        "spark.sql(\"\"\"SELECT e.Department,ROUND(COUNT(CASE WHEN a.Status='Present' THEN 1 END)*1.0/COUNT(*)) AS AttendanceRate\n",
        "          FROM hr.employees e\n",
        "          JOIN hr.attendance a ON e.EmpID = a.EmpID\n",
        "          GROUP BY e.Department\n",
        "          \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tOYtslKzuJD",
        "outputId": "960f9818-40cf-4927-c812-1da7195e439b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "| Department|AttendanceRate|\n",
            "+-----------+--------------+\n",
            "|Engineering|             1|\n",
            "|         HR|             1|\n",
            "|  Marketing|             0|\n",
            "+-----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write SQL queries:\n",
        "# Employees joined after 2021 with salary > 70,000.\n",
        "spark.sql(\"\"\"SELECT * FROM hr.employees\n",
        "          WHERE YEAR(JoinDate) > 2021 AND Salary > 70000\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zPEGkzn0hXv",
        "outputId": "50c7aaab-0c7b-46e8-c9c7-16de47539b83"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92|    2022|        7|    ******|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Advanced (Optional)\n"
      ],
      "metadata": {
        "id": "xgYZWDsL0yMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a UDF to classify department as \"Tech\" vs \"Non-Tech\".\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def classify_dept(dept):\n",
        "    if dept == \"Engineering\":\n",
        "      return \"Tech\"\n",
        "    else:\n",
        "      return \"Non-Tech\"\n",
        "dept_udf = udf(classify_dept, StringType())\n",
        "classified_df = employees_df.withColumn(\"DeptType\", dept_udf(col(\"Department\")))\n",
        "classified_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPm8YUh402UT",
        "outputId": "7d3b8542-c39e-4995-8da0-084578b3b077"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+--------+\n",
            "|EmpID|  Name| Department|  JoinDate|Salary|ManagerID|TenureYears|JoinYear|JoinMonth|MaskedName|DeptType|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+--------+\n",
            "|    1| Anita|         HR|2021-05-01| 55000|     NULL|       4.11|    2021|        5|     *****|Non-Tech|\n",
            "|    2|   Raj|Engineering|2020-03-15| 80000|        1|       5.24|    2020|        3|       ***|    Tech|\n",
            "|    3|Simran|Engineering|2022-07-10| 75000|        1|       2.92|    2022|        7|    ******|    Tech|\n",
            "|    4| Aamir|  Marketing|2019-11-20| 60000|        1|       5.56|    2019|       11|     *****|Non-Tech|\n",
            "|    5| Nisha|         HR|2023-01-05| 50000|        1|       2.43|    2023|        1|     *****|Non-Tech|\n",
            "+-----+------+-----------+----------+------+---------+-----------+--------+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a view emp_attendance_summary .\n",
        "attendance_stats.createOrReplaceTempView(\"emp_attendance_summary\")\n",
        "spark.sql(\"SELECT * FROM emp_attendance_summary\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poLQ7PxN1KnT",
        "outputId": "43803bb7-ac2e-4c51-fb6d-87d9e01d31ca"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+-----------+-----------------+\n",
            "|EmpID|TotalDays|PresentDays|AttendancePercent|\n",
            "+-----+---------+-----------+-----------------+\n",
            "|    1|        2|          2|            100.0|\n",
            "|    3|        2|          2|            100.0|\n",
            "|    5|        2|          2|            100.0|\n",
            "|    4|        2|          0|              0.0|\n",
            "|    2|        2|          1|             50.0|\n",
            "+-----+---------+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save it as Parquet partitioned by Department .\n",
        "summary_df=attendance_stats.join(employees_df.select(\"EmpID\", \"Department\"),on=\"EmpID\",how=\"left\")\n",
        "summary_df.write.mode(\"overwrite\").partitionBy(\"Department\").parquet(\"/contents/drive/MyDrive/emp_attendance_summary_parquet\")\n",
        "parquet_df=spark.read.parquet(\"/contents/drive/MyDrive/emp_attendance_summary_parquet\")\n",
        "parquet_df.printSchema()\n",
        "parquet_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFnjqM0z1mS0",
        "outputId": "ac08f0e9-f78d-485f-a1b8-6669d6b24226"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- EmpID: integer (nullable = true)\n",
            " |-- TotalDays: long (nullable = true)\n",
            " |-- PresentDays: long (nullable = true)\n",
            " |-- AttendancePercent: double (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            "\n",
            "+-----+---------+-----------+-----------------+-----------+\n",
            "|EmpID|TotalDays|PresentDays|AttendancePercent| Department|\n",
            "+-----+---------+-----------+-----------------+-----------+\n",
            "|    1|        2|          2|            100.0|         HR|\n",
            "|    5|        2|          2|            100.0|         HR|\n",
            "|    3|        2|          2|            100.0|Engineering|\n",
            "|    2|        2|          1|             50.0|Engineering|\n",
            "|    4|        2|          0|              0.0|  Marketing|\n",
            "+-----+---------+-----------+-----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}