{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIOBBwiFMq7y",
        "outputId": "0babc42f-99a5-4bd6-e73c-fbb3daba5ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if 'spark' in locals() and isinstance(spark, SparkSession):\n",
        "#     print(\"Stopping existing SparkSession...\")\n",
        "#     spark.stop()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "AC5K3ZndOJ4i",
        "outputId": "ecd0b72b-282b-4176-dd92-9df3abd83e40"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb4e46a6c50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4eb4c3180292:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Ingestion & Exploration"
      ],
      "metadata": {
        "id": "kjB3wjoJOYlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load both CSV files with schema inference.\n",
        "customers_df=spark.read.csv(\"/content/drive/MyDrive/customers.csv\",header=True,inferSchema=True)\n",
        "orders_df=spark.read.csv(\"/content/drive/MyDrive/orders.csv\",header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "KSPhebjHOdJU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all columns and data types.\n",
        "print(\"Customer Schema:\")\n",
        "customers_df.printSchema()\n",
        "print(\"Order Schema:\")\n",
        "orders_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuXKKuhyPUiF",
        "outputId": "3c1b5945-c044-4de7-fd25-06e69fa1a487"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customer Schema:\n",
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- SignupDate: date (nullable = true)\n",
            "\n",
            "Order Schema:\n",
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of customers and orders.\n",
        "print(\"Total number of customers:\",customers_df.count())\n",
        "print(\"Total number of orders:\",orders_df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKyEU5znP1Sx",
        "outputId": "013f36ac-b559-49ad-fdf2-998d6a5b496e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of customers: 5\n",
            "Total number of orders: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show distinct cities.\n",
        "print(\"Distinct cities:\")\n",
        "customers_df.select(\"city\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi5eXHlCP9k8",
        "outputId": "f54f17b9-6a9d-49fa-9efc-b632b1162a7f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct cities:\n",
            "+---------+\n",
            "|     city|\n",
            "+---------+\n",
            "|Bangalore|\n",
            "|  Chennai|\n",
            "|   Mumbai|\n",
            "|    Delhi|\n",
            "|Hyderabad|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. DataFrame Transformations"
      ],
      "metadata": {
        "id": "BVyJAv0kQFpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a column TotalAmount = Price * Quantity .\n",
        "from pyspark.sql.functions import col\n",
        "orders_df=orders_df.withColumn(\"TotalAmount\",col(\"Price\")*col(\"Quantity\"))\n",
        "orders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCvg5DWLQI0t",
        "outputId": "9cd4b26d-5fb5-49d4-eeff-6e806ec60076"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column OrderYear from OrderDate .\n",
        "from pyspark.sql.functions import year,to_date\n",
        "orders_df=orders_df.withColumn(\"OrderDate\",to_date(\"OrderDate\",\"yyyy-MM-dd\"))\n",
        "orders_df=orders_df.withColumn(\"OrderYear\",year(col(\"OrderDate\")))\n",
        "orders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5s7J522QlEK",
        "outputId": "8fce5990-799b-4493-e8b0-400177c9573f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter orders with TotalAmount > 10,000 .\n",
        "orders_df.filter(col(\"TotalAmount\")>10000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NqDVzO3QuS7",
        "outputId": "7c84bc73-814f-473b-fefb-74c8fe3c95ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the Email column from customers\n",
        "customers_df=customers_df.drop(\"Email\")\n",
        "customers_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R90gCzCRVGh",
        "outputId": "d7a9dc83-baff-44cb-ab4a-083b13e3bf29"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+----------+\n",
            "|CustomerID| Name|     City|SignupDate|\n",
            "+----------+-----+---------+----------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|\n",
            "|       102| Neha|    Delhi|2023-01-15|\n",
            "|       103| Ravi|Bangalore|2021-11-01|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|\n",
            "|       105| Amit|  Chennai|2023-03-10|\n",
            "+----------+-----+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Handling Nulls & Conditionals"
      ],
      "metadata": {
        "id": "jwD_qQkoRlRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate a null in City and fill it with “Unknown”.\n",
        "from pyspark.sql.functions import when\n",
        "customers_df=customers_df.withColumn(\"City\",when(col(\"CustomerID\")==105,None).otherwise(col(\"City\")))\n",
        "customers_df=customers_df.fillna({\"City\":\"Unknown\"})\n",
        "customers_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPl6knzDRo0R",
        "outputId": "d41c77b7-3f30-4026-f6cc-b34fa33a7bdb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+----------+\n",
            "|CustomerID| Name|     City|SignupDate|\n",
            "+----------+-----+---------+----------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|\n",
            "|       102| Neha|    Delhi|2023-01-15|\n",
            "|       103| Ravi|Bangalore|2021-11-01|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|\n",
            "|       105| Amit|  Unknown|2023-03-10|\n",
            "+----------+-----+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label customers as “Loyal” if SignupDate is before 2022, else “New”.\n",
        "from pyspark.sql.functions import to_date, lit\n",
        "customers_df=customers_df.withColumn(\"SignupDate\",to_date(\"SignupDate\",\"yyyy-MM-dd\"))\n",
        "customers_df=customers_df.withColumn(\"CustomerType\",when(col(\"SignupDate\")<lit(\"2022-01-01\"),\"Loyal\").otherwise(\"New\"))\n",
        "customers_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zGYqhpqSJq5",
        "outputId": "0862ad42-7e2a-4412-f5e9-6ef3a5b7fc26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+----------+------------+\n",
            "|CustomerID| Name|     City|SignupDate|CustomerType|\n",
            "+----------+-----+---------+----------+------------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|\n",
            "|       102| Neha|    Delhi|2023-01-15|         New|\n",
            "|       103| Ravi|Bangalore|2021-11-01|       Loyal|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|       Loyal|\n",
            "|       105| Amit|  Unknown|2023-03-10|         New|\n",
            "+----------+-----+---------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create OrderType column: \"Low\" if < 􀀀5,000, \"High\" if ≥ 􀀀5,000.\n",
        "orders_df=orders_df.withColumn(\"OrderType\",when(col(\"TotalAmount\")<5000,\"Low\").otherwise(\"High\"))\n",
        "orders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w71Bb9MS4W6",
        "outputId": "dd371479-090e-4b1a-f782-0415f9a5cdaa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|      Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Joins & Aggregations"
      ],
      "metadata": {
        "id": "nA7zj-2OTDRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join customers and orders on CustomerID .\n",
        "joined_df=customers_df.join(orders_df,on=\"CustomerID\",how=\"inner\")\n",
        "joined_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5aLOU1iTGvS",
        "outputId": "63f4d748-b8ae-4ec6-f515-14ae7034693f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|CustomerID| Name|     City|SignupDate|CustomerType|OrderID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      1|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      2|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|\n",
            "|       102| Neha|    Delhi|2023-01-15|         New|      3|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|       103| Ravi|Bangalore|2021-11-01|       Loyal|      4|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|       Loyal|      5|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|\n",
            "|       105| Amit|  Unknown|2023-03-10|         New|      6| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|      Low|\n",
            "|       102| Neha|    Delhi|2023-01-15|         New|      7|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total orders and revenue per city.\n",
        "from pyspark.sql.functions import count, sum\n",
        "joined_df.groupBy(\"City\").agg(count(\"OrderID\").alias(\"TotalOrders\"),sum(\"TotalAmount\").alias(\"TotalRevenue\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBbPW0-qTOBh",
        "outputId": "89fd7b92-0560-47b2-a361-64dcd20568d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+------------+\n",
            "|     City|TotalOrders|TotalRevenue|\n",
            "+---------+-----------+------------+\n",
            "|Bangalore|          1|      3500.0|\n",
            "|   Mumbai|          2|    101200.0|\n",
            "|  Unknown|          1|      2500.0|\n",
            "|    Delhi|          2|     50000.0|\n",
            "|Hyderabad|          1|      5000.0|\n",
            "+---------+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show top 3 customers by total spend.\n",
        "from pyspark.sql.functions import desc\n",
        "joined_df.groupBy(\"CustomerID\").agg(sum(\"TotalAmount\").alias(\"TotalSpend\")).orderBy(desc(\"TotalSpend\")).limit(3).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujJ88VsETsdy",
        "outputId": "9a141850-df5c-4f45-b4c3-7588e8eba9fe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|CustomerID|TotalSpend|\n",
            "+----------+----------+\n",
            "|       101|  101200.0|\n",
            "|       102|   50000.0|\n",
            "|       104|    5000.0|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many products each category has sold.\n",
        "joined_df.groupBy(\"Category\").agg(sum(\"Quantity\").alias(\"TotalSold\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_foO63_1T3Xu",
        "outputId": "6e4952f8-d0c2-4e4c-9f24-98926e495940"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+\n",
            "|   Category|TotalSold|\n",
            "+-----------+---------+\n",
            "| Stationery|        5|\n",
            "|Electronics|        5|\n",
            "|  Furniture|        1|\n",
            "| Appliances|        1|\n",
            "+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Spark SQL Tasks"
      ],
      "metadata": {
        "id": "cmQ55KakUKLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create database sales and switch to it.\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS sales\")\n",
        "spark.sql(\"USE sales\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_HMVdnfUTWL",
        "outputId": "467c9f03-8daa-4a29-b770-f2c8a5e57833"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save both datasets as tables in the sales database.\n",
        "customers_df.write.mode(\"overwrite\").saveAsTable(\"sales.customers\")\n",
        "orders_df.write.mode(\"overwrite\").saveAsTable(\"sales.orders\")"
      ],
      "metadata": {
        "id": "Iu0bygFJUI8T"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write SQL to:\n",
        "# List all orders by customers from “Delhi”.\n",
        "spark.sql(\"\"\"SELECT o.*\n",
        "    FROM sales.orders o\n",
        "    JOIN sales.customers c ON o.CustomerID = c.CustomerID\n",
        "    WHERE c.City = 'Delhi'\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfmmBTVeU3DD",
        "outputId": "44a2e09f-6063-44dc-beca-ffb74abe2371"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write SQL to:\n",
        "# Find average order value in each category.\n",
        "spark.sql(\"\"\"SELECT Category, AVG(TotalAmount) AS AvgOrderValue\n",
        "    FROM sales.orders\n",
        "    GROUP BY Category\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68H3nIqbVGfY",
        "outputId": "a539d3f6-aee6-4b24-c9cc-ac75c4ba1eec"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+\n",
            "|   Category|AvgOrderValue|\n",
            "+-----------+-------------+\n",
            "| Stationery|       2500.0|\n",
            "|Electronics|      37800.0|\n",
            "|  Furniture|       3500.0|\n",
            "| Appliances|       5000.0|\n",
            "+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write SQL to:\n",
        "# Create a view monthly_orders with month-wise total amount.\n",
        "spark.sql(\"\"\"CREATE OR REPLACE VIEW sales.monthly_orders AS\n",
        "    SELECT MONTH(OrderDate) AS Month, SUM(TotalAmount) AS TotalAmount\n",
        "    FROM sales.orders\n",
        "    GROUP BY MONTH(OrderDate)\"\"\")\n",
        "spark.sql(\"SELECT * FROM monthly_orders\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLAkXxv_Vujg",
        "outputId": "f5c622df-519f-46e7-8db9-9200f528bb74"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+\n",
            "|Month|TotalAmount|\n",
            "+-----+-----------+\n",
            "|    1|   101200.0|\n",
            "|    3|    32500.0|\n",
            "|    2|    28500.0|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. String & Date Functions"
      ],
      "metadata": {
        "id": "8I3EA9PPWFFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask emails using regex.\n",
        "from pyspark.sql.functions import regexp_extract,lit,concat,col\n",
        "masked_df=customers_df.withColumn(\"MaskedEmail\",concat(regexp_extract(col(\"Email\"),r'^(.).*@',1),lit(\"***\"),regexp_extract(col(\"Email\"),r'@.*',0)))\n",
        "masked_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f-tYwNuWMNl",
        "outputId": "8aa54f8c-464a-4145-be04-475264b96151"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+----------------+\n",
            "|CustomerID|Name |Email            |City     |SignupDate|MaskedEmail     |\n",
            "+----------+-----+-----------------+---------+----------+----------------+\n",
            "|101       |Ali  |ali@gmail.com    |Mumbai   |2022-05-10|a***@gmail.com  |\n",
            "|102       |Neha |neha@yahoo.com   |Delhi    |2023-01-15|n***@yahoo.com  |\n",
            "|103       |Ravi |ravi@hotmail.com |Bangalore|2021-11-01|r***@hotmail.com|\n",
            "|104       |Sneha|sneha@outlook.com|Hyderabad|2020-07-22|s***@outlook.com|\n",
            "|105       |Amit |amit@gmail.com   |Chennai  |2023-03-10|a***@gmail.com  |\n",
            "+----------+-----+-----------------+---------+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate Name and City as “Name from City”.\n",
        "from pyspark.sql.functions import concat_ws\n",
        "concat_df=customers_df.withColumn(\"NameFromCity\",concat_ws(\" from \",col(\"Name\"),col(\"City\")))\n",
        "concat_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztfgol_eYiF9",
        "outputId": "bd9fc3db-6fc8-4395-cba1-2387f3df62a3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+--------------------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|        NameFromCity|\n",
            "+----------+-----+-----------------+---------+----------+--------------------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|     Ali from Mumbai|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|     Neha from Delhi|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01| Ravi from Bangalore|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|Sneha from Hyderabad|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|   Amit from Chennai|\n",
            "+----------+-----+-----------------+---------+----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use datediff() to calculate customer age in days.\n",
        "from pyspark.sql.functions import datediff,to_date,current_date\n",
        "customers_df=customers_df.withColumn(\"SignupDate\",to_date(\"SignupDate\"))\n",
        "customers_df=customers_df.withColumn(\"AgeInDays\",datediff(current_date(),col(\"SignupDate\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNpwKzwEY16Z",
        "outputId": "98a5ae7e-17e3-4f84-e4bd-632f4001fed9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+---------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|AgeInDays|\n",
            "+----------+-----+-----------------+---------+----------+---------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|     1126|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|      876|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01|     1316|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|     1783|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|      822|\n",
            "+----------+-----+-----------------+---------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract month name from OrderDate .\n",
        "from pyspark.sql.functions import date_format\n",
        "orders_df=orders_df.withColumn(\"MonthName\",date_format(\"OrderDate\",\"MMMM\"))\n",
        "orders_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHO0rKEWZRhm",
        "outputId": "256f821b-39b8-41a8-ceca-916dd0e20702"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|MonthName|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|  January|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|  January|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01| February|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10| February|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15| February|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|    March|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    March|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. UDFs and Complex Logic"
      ],
      "metadata": {
        "id": "eylthOEdZpz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a UDF to tag customers:\n",
        "# “Gold” if spend > 􀀀50K, “Silver” if 10K–50K, “Bronze” if <10K.\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", orders_df[\"Quantity\"] * orders_df[\"Price\"])\n",
        "spend_df = orders_df.groupBy(\"CustomerID\").sum(\"TotalAmount\").withColumnRenamed(\"sum(TotalAmount)\", \"TotalSpend\")\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def loyalty(spend):\n",
        "    if spend>50000:\n",
        "        return \"Gold\"\n",
        "    elif 10000<=spend<=50000:\n",
        "        return \"Silver\"\n",
        "    else:\n",
        "        return \"Bronze\"\n",
        "\n",
        "loyalty_udf = udf(loyalty, StringType())\n",
        "tagged=spend_df.withColumn(\"Loyalty\",loyalty_udf(col(\"TotalSpend\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goXVsR9AZvcx",
        "outputId": "76abb4dd-0904-44ff-a74b-95088045779e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+-------+\n",
            "|CustomerID|TotalSpend|Loyalty|\n",
            "+----------+----------+-------+\n",
            "|       101|  101200.0|   Gold|\n",
            "|       103|    3500.0| Bronze|\n",
            "|       102|   50000.0| Silver|\n",
            "|       105|    2500.0| Bronze|\n",
            "|       104|    5000.0| Bronze|\n",
            "+----------+----------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a UDF to shorten product names (first 3 letters + ...).\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def shorten_name(name):\n",
        "    if len(name) > 3:\n",
        "        return name[:3] + \"...\"\n",
        "    else:\n",
        "        return name\n",
        "\n",
        "shorten_udf = udf(shorten_name, StringType())\n",
        "orders_df.withColumn(\"ShortProduct\", shorten_udf(col(\"Product\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MH8i7nfa6tJ",
        "outputId": "0dfe6b11-94a9-4767-ee05-9cc9083835c1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+---------+-----------+------------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|MonthName|TotalAmount|ShortProduct|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+---------+-----------+------------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|  January|   100000.0|      Lap...|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|  January|     1200.0|      Mou...|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01| February|    20000.0|      Tab...|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10| February|     3500.0|      Boo...|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15| February|     5000.0|      Mix...|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|    March|     2500.0|      Not...|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    March|    30000.0|      Pho...|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+---------+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Parquet & Views"
      ],
      "metadata": {
        "id": "jOcjtGFsbZY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the joined result as a Parquet file.\n",
        "joined_df.write.mode(\"overwrite\").parquet(\"/content/drive/MyDrive/joined_data.parquet\")"
      ],
      "metadata": {
        "id": "zquNNNncZfPE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read it back and verify schema.\n",
        "parquet_df=spark.read.parquet(\"/content/drive/MyDrive/joined_data.parquet\")\n",
        "parquet_df.printSchema()\n",
        "parquet_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iG0wiXBbmcQ",
        "outputId": "5aa5206c-229c-4d6c-d352-aefc7dc050a8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- SignupDate: date (nullable = true)\n",
            " |-- CustomerType: string (nullable = true)\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            " |-- TotalAmount: double (nullable = true)\n",
            " |-- OrderYear: integer (nullable = true)\n",
            " |-- OrderType: string (nullable = true)\n",
            "\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|CustomerID| Name|     City|SignupDate|CustomerType|OrderID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      1|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      2|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|\n",
            "|       102| Neha|    Delhi|2023-01-15|         New|      3|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|       103| Ravi|Bangalore|2021-11-01|       Loyal|      4|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|       Loyal|      5|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|\n",
            "|       105| Amit|  Unknown|2023-03-10|         New|      6| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|      Low|\n",
            "|       102| Neha|    Delhi|2023-01-15|         New|      7|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and query a global temp view.\n",
        "parquet_df.createOrReplaceGlobalTempView(\"global_orders\")\n",
        "spark.sql(\"SELECT * FROM global_temp.global_orders\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF6ebEpEb2uT",
        "outputId": "bacdb690-f2c8-4229-8d2c-50bd539c50b6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|CustomerID| Name|     City|SignupDate|CustomerType|OrderID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      1|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      2|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|\n",
            "|       102| Neha|    Delhi|2023-01-15|         New|      3|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|       103| Ravi|Bangalore|2021-11-01|       Loyal|      4|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|       Loyal|      5|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|\n",
            "|       105| Amit|  Unknown|2023-03-10|         New|      6| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|      Low|\n",
            "|       102| Neha|    Delhi|2023-01-15|         New|      7|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare performance between CSV read and Parquet read.\n",
        "import time\n",
        "start_csv=time.time()\n",
        "csv_df=spark.read.csv(\"/content/drive/MyDrive/orders.csv\",header=True)\n",
        "print(\"CSV read time:\",time.time()-start_csv)\n",
        "start_parquet=time.time()\n",
        "parquet_df=spark.read.parquet(\"/content/drive/MyDrive/joined_data.parquet\")\n",
        "print(\"Parquet read time:\",time.time()-start_parquet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NkTDuyncMxv",
        "outputId": "a04789eb-1296-4a46-fcc5-e6d6e41fb182"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV read time: 0.27532172203063965\n",
            "Parquet read time: 0.31235337257385254\n"
          ]
        }
      ]
    }
  ]
}