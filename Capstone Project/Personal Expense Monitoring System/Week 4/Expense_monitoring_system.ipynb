{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba923492-5b4a-4f70-a38f-cdd9686de5f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=2806829887576824#setting/sparkui/0612-043650-nhuexwr6/driver-7243797827306264588\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x786d990cd590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Expense monitoring\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad37d38b-6615-495b-a794-7561b0f1ec86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+------------+--------------------+\n|user_id|            category|amount|expense_date|         description|\n+-------+--------------------+------+------------+--------------------+\n|      1|   Utilities & Bills|1200.0|  2025-06-01| BSNL broadband bill|\n|      1|                Food| 850.0|  2025-05-03|Dinner at Saravan...|\n|      2|           Transport|1000.0|  2025-05-02|Uber ride to airport|\n|      2|          Healthcare| 450.0|  2025-05-04|Doctor visit and ...|\n|      2|Savings & Investm...|3000.0|  2025-05-05|Monthly SIP in Ax...|\n+-------+--------------------+------+------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Load expenses data\n",
    "expenses_df = spark.read.format(\"csv\").option(\"header\", True).load(\"file:/Workspace/Shared/expenses_cleaned.csv\")\n",
    "expenses_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "022d5bde-ded7-4ab4-abe6-8ef17df90cb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+--------------------+\n|user_id|         name|               email|\n+-------+-------------+--------------------+\n|      1|Ananya Sharma|ananya.sharma@exa...|\n|      2|  Rahul Verma|rahul.verma@examp...|\n+-------+-------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Load user data\n",
    "users_df = spark.read.format(\"csv\").option(\"header\", True).load(\"file:/Workspace/Shared/users.csv\")\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14559f9a-328e-4b57-a597-bf2c2ce82b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------+------------+--------------------+-------------+--------------------+\n|user_id|            category|amount|expense_date|         description|         name|               email|\n+-------+--------------------+------+------------+--------------------+-------------+--------------------+\n|      1|   Utilities & Bills|1200.0|  2025-06-01| BSNL broadband bill|Ananya Sharma|ananya.sharma@exa...|\n|      1|                Food| 850.0|  2025-05-03|Dinner at Saravan...|Ananya Sharma|ananya.sharma@exa...|\n|      2|           Transport|1000.0|  2025-05-02|Uber ride to airport|  Rahul Verma|rahul.verma@examp...|\n|      2|          Healthcare| 450.0|  2025-05-04|Doctor visit and ...|  Rahul Verma|rahul.verma@examp...|\n|      2|Savings & Investm...|3000.0|  2025-05-05|Monthly SIP in Ax...|  Rahul Verma|rahul.verma@examp...|\n+-------+--------------------+------+------------+--------------------+-------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Join user and expense data\n",
    "combined_df = expenses_df.join(users_df, on=\"user_id\", how=\"inner\")\n",
    "combined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21d008a8-4e69-473a-a3df-2c63d687479f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+-------------+------+\n|user_id|year|month|monthly_spend| alert|\n+-------+----+-----+-------------+------+\n|      2|2025|    5|       4450.0|Normal|\n|      1|2025|    6|       1200.0|Normal|\n|      1|2025|    5|        850.0|Normal|\n+-------+----+-----+-------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create monthly summary with alerts\n",
    "from pyspark.sql.functions import month, year, sum as _sum, when,col\n",
    "\n",
    "summary_df = combined_df .withColumn(\"month\", month(\"expense_date\")) \\\n",
    "    .withColumn(\"year\", year(\"expense_date\")) \\\n",
    "    .groupBy(\"user_id\", \"year\", \"month\") \\\n",
    "    .agg(_sum(\"amount\").alias(\"monthly_spend\")) \\\n",
    "    .withColumn(\"alert\", when(col(\"monthly_spend\") > 20000, \"High Spend\").otherwise(\"Normal\"))\n",
    "summary_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66685543-69c3-4225-a54e-a75f12c17b47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save to Delta and CSV formats\n",
    "summary_df.write.format(\"delta\").mode(\"overwrite\").save(\"file:/Workspace/Shared/expense_summary_delta\")\n",
    "summary_df.write.format(\"csv\").option(\"header\", True).mode(\"overwrite\").save(\"file:/Workspace/Shared/expense_summary_csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Expense_monitoring_system",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}