{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d28b0e1-b682-4a6c-a0cf-9cfd8e8b1393",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=2806829887576824#setting/sparkui/0612-043650-nhuexwr6/driver-5348643725428426966\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x77ddf6ecd410>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark DataFrames\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4016c40-7146-407c-a3de-55d1c37775ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------------------------------------------------+------+------+\n|OrderID|Customer|Items                                                         |Region|Amount|\n+-------+--------+--------------------------------------------------------------+------+------+\n|101    |Ali     |[{Product -> Laptop, Qty -> 1}, {Product -> Mouse, Qty -> 2}] |Asia  |1200.0|\n|102    |Zara    |[{Product -> Tablet, Qty -> 1}]                               |Europe|650.0 |\n|103    |Mohan   |[{Product -> Phone, Qty -> 2}, {Product -> Charger, Qty -> 1}]|Asia  |890.0 |\n|104    |Sara    |[{Product -> Desk, Qty -> 1}]                                 |US    |450.0 |\n+-------+--------+--------------------------------------------------------------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "data = [\n",
    "    Row(OrderID=101, Customer=\"Ali\", Items=[{\"Product\":\"Laptop\", \"Qty\":1}, {\"Product\":\"Mouse\", \"Qty\":2}], Region=\"Asia\", Amount=1200.0),\n",
    "    Row(OrderID=102, Customer=\"Zara\", Items=[{\"Product\":\"Tablet\", \"Qty\":1}], Region=\"Europe\", Amount=650.0),\n",
    "    Row(OrderID=103, Customer=\"Mohan\", Items=[{\"Product\":\"Phone\", \"Qty\":2}, {\"Product\":\"Charger\", \"Qty\":1}], Region=\"Asia\", Amount=890.0),\n",
    "    Row(OrderID=104, Customer=\"Sara\", Items=[{\"Product\":\"Desk\", \"Qty\":1}], Region=\"US\", Amount=450.0)\n",
    "]\n",
    "df_sales = spark.createDataFrame(data)\n",
    "df_sales.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ec22a2-467b-46c7-bd3b-07926d7efd5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Working with JSON & Nested Fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4234ae2-667a-441c-b5f5-2a7da73d35ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+------+-------+---+\n|OrderID|Customer|Region|Amount|Product|Qty|\n+-------+--------+------+------+-------+---+\n|    101|     Ali|  Asia|1200.0| Laptop|  1|\n|    101|     Ali|  Asia|1200.0|  Mouse|  2|\n|    102|    Zara|Europe| 650.0| Tablet|  1|\n|    103|   Mohan|  Asia| 890.0|  Phone|  2|\n|    103|   Mohan|  Asia| 890.0|Charger|  1|\n|    104|    Sara|    US| 450.0|   Desk|  1|\n+-------+--------+------+------+-------+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col, when\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1911c3a6-ec09-419c-b90b-dbc8a085a513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n|Product|TotalQty|\n+-------+--------+\n| Laptop|       1|\n|  Mouse|       2|\n| Tablet|       1|\n|  Phone|       2|\n|Charger|       1|\n|   Desk|       1|\n+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# 2. Count total quantity sold per product\n",
    "from pyspark.sql.types import IntegerType\n",
    "df_flat = df_flat.withColumn(\"Qty\", col(\"Qty\").cast(IntegerType()))\n",
    "df_flat.groupBy(\"Product\").sum(\"Qty\").withColumnRenamed(\"sum(Qty)\", \"TotalQty\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de371394-5f75-4b8c-b23e-b6c3247524b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n|Region|OrderCount|\n+------+----------+\n|  Asia|         2|\n|Europe|         1|\n|    US|         1|\n+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 3. Count number of orders per region\n",
    "df_sales.groupBy(\"Region\").count().withColumnRenamed(\"count\", \"OrderCount\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c9af20a-189f-4e1c-9052-8f702ca7c1e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using when and otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95fc6452-0262-4980-b53d-fe6163035c89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------+\n|OrderID|Amount|HighValueOrder|\n+-------+------+--------------+\n|    101|1200.0|           Yes|\n|    102| 650.0|            No|\n|    103| 890.0|            No|\n|    104| 450.0|            No|\n+-------+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 4. Create a new column HighValueOrder :\n",
    "# \"Yes\" if Amount > 1000\n",
    "# \"No\" otherwise\n",
    "df_sales = df_sales.withColumn(\"HighValueOrder\", when(col(\"Amount\") > 1000, \"Yes\").otherwise(\"No\"))\n",
    "df_sales.select(\"OrderID\", \"Amount\", \"HighValueOrder\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "420f8d90-3308-4df4-959c-7d0030f57337",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n|Region|ShippingZone|\n+------+------------+\n|  Asia|      Zone A|\n|Europe|      Zone B|\n|    US|      Zone C|\n+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 5. Add a column ShippingZone :\n",
    "# Asia → \"Zone A\", Europe → \"Zone B\", US → \"Zone C\"\n",
    "df_sales = df_sales.withColumn(\"ShippingZone\", \n",
    "    when(col(\"Region\") == \"Asia\", \"Zone A\")\n",
    "    .when(col(\"Region\") == \"Europe\", \"Zone B\")\n",
    "    .when(col(\"Region\") == \"US\", \"Zone C\")\n",
    "    .otherwise(\"Other\"))\n",
    "df_sales.select(\"Region\", \"ShippingZone\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9802563-ab82-4daf-a92e-84a29726638d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Temporary & Permanent Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29013481-2c0a-4def-bb93-e3a11636b300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Register df_sales as a temporary view named sales_view .\n",
    "df_sales.createOrReplaceTempView(\"sales_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab6fd84-bab7-49b1-8ba1-470fd143954b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------+\n|Region|OrderCount|AvgAmount|\n+------+----------+---------+\n|  Asia|         2|   1045.0|\n|Europe|         1|    650.0|\n|    US|         1|    450.0|\n+------+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# 7. Write a SQL query to:\n",
    "# Count orders by Region\n",
    "# Find average amount per region\n",
    "spark.sql(\"\"\"SELECT Region,\n",
    "           COUNT(*) AS OrderCount,\n",
    "           ROUND(AVG(Amount), 2) AS AvgAmount\n",
    "    FROM sales_view\n",
    "    GROUP BY Region\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8572f630-d96d-4646-a2f9-da03a8d7e365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 8. Create a permanent view using saveAsTable()\n",
    "df_sales.write.mode(\"overwrite\").saveAsTable(\"permanent_sales_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bb48eab-8c4f-4263-9792-7cd85eda8e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "SQL Queries via Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8231581-f8b2-4a4c-be57-a93663e7d851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+------+\n|OrderID|Customer|Region|Amount|\n+-------+--------+------+------+\n|    101|     Ali|  Asia|1200.0|\n|    103|   Mohan|  Asia| 890.0|\n+-------+--------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. Use SQL to filter all orders with more than 1 item.\n",
    "spark.sql(\"\"\"SELECT OrderID, Customer, Region, Amount\n",
    "    FROM sales_view\n",
    "    WHERE size(Items) > 1\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b11a5e9-29e8-4883-aa2a-e6588e04351d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|Customer|\n+--------+\n|     Ali|\n|   Mohan|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# 10. Use SQL to extract customer names where Amount > 800.\n",
    "spark.sql(\"\"\"SELECT Customer\n",
    "    FROM sales_view\n",
    "    WHERE Amount > 800\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdbd812e-1017-4570-a44b-84fceec865d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Saving as Parquet and Reading Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9bb6b02-e5b1-4c42-b731-2bc488d150af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 11. Save exploded product-level DataFrame as partitioned Parquet by Region\n",
    "df_flat.write.mode(\"overwrite\").partitionBy(\"Region\").parquet(\"/shared/sales_by_region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b79bf8b-4d5c-4f0d-8978-9c0891d033a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n|Product|count|\n+-------+-----+\n|  Phone|    1|\n|Charger|    1|\n| Laptop|    1|\n|  Mouse|    1|\n| Tablet|    1|\n|   Desk|    1|\n+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 12. Read the Parquet and group by Product\n",
    "df_parquet = spark.read.parquet(\"/mnt/output/sales_by_region\")\n",
    "df_parquet.groupBy(\"Product\").count().show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-06-12 10:03:02",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}